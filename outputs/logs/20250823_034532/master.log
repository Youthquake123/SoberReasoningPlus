==== RUN_ID: 20250823_034532 ====
Start: 2025-08-23T03:45:32+00:00
HOST: yibiaoy-7b-test-worker-0
CWD: /
--- GPU Info ---
Sat Aug 23 03:45:32 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:10:1C.0 Off |                    0 |
| N/A   48C    P0             57W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  |   00000000:10:1D.0 Off |                    0 |
| N/A   44C    P0             57W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-40GB          On  |   00000000:20:1C.0 Off |                    0 |
| N/A   48C    P0             62W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-40GB          On  |   00000000:20:1D.0 Off |                    0 |
| N/A   44C    P0             62W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100-SXM4-40GB          On  |   00000000:90:1C.0 Off |                    0 |
| N/A   47C    P0             59W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100-SXM4-40GB          On  |   00000000:90:1D.0 Off |                    0 |
| N/A   44C    P0             56W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100-SXM4-40GB          On  |   00000000:A0:1C.0 Off |                    0 |
| N/A   47C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100-SXM4-40GB          On  |   00000000:A0:1D.0 Off |                    0 |
| N/A   44C    P0             62W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
--- Key Python pkgs ---
torch==2.7.0+cu126
triton==3.3.0
vllm==0.9.2
xformers==0.0.30
--- Env snapshot (filtered) ---
NV_CUDNN_PACKAGE_NAME=libcudnn9-cuda-12
NVIDIA_REQUIRE_CUDA=cuda>=12.6 brand=unknown,driver>=470,driver<471 brand=grid,driver>=470,driver<471 brand=tesla,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=vapps,driver>=470,driver<471 brand=vpc,driver>=470,driver<471 brand=vcs,driver>=470,driver<471 brand=vws,driver>=470,driver<471 brand=cloudgaming,driver>=470,driver<471 brand=unknown,driver>=535,driver<536 brand=grid,driver>=535,driver<536 brand=tesla,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=vapps,driver>=535,driver<536 brand=vpc,driver>=535,driver<536 brand=vcs,driver>=535,driver<536 brand=vws,driver>=535,driver<536 brand=cloudgaming,driver>=535,driver<536 brand=unknown,driver>=550,driver<551 brand=grid,driver>=550,driver<551 brand=tesla,driver>=550,driver<551 brand=nvidia,driver>=550,driver<551 brand=quadro,driver>=550,driver<551 brand=quadrortx,driver>=550,driver<551 brand=nvidiartx,driver>=550,driver<551 brand=vapps,driver>=550,driver<551 brand=vpc,driver>=550,driver<551 brand=vcs,driver>=550,driver<551 brand=vws,driver>=550,driver<551 brand=cloudgaming,driver>=550,driver<551
TORCH_NVCC_FLAGS=-Xfatbin -compress-all
CUDA_CACHE_DISABLE=1
TORCH_CUDA_ARCH_LIST=5.2 6.0 6.1 7.0 7.2 7.5 8.0 8.6 8.7 9.0+PTX
NCCL_VERSION=2.23.4-1
NCCL_SOCKET_IFNAME=eth0
NV_CUDNN_PACKAGE=libcudnn9-cuda-12=9.5.1.17-1
NVIDIA_DRIVER_CAPABILITIES=compute,utility
NCCL_HOME=/opt/nccl
NCCL_P2P_LEVEL=NVL
NCCL_DEBUG=WARN
VLLM_WORKER_MULTIPROC_METHOD=spawn
NCCL_TIMEOUT=7200
NVIDIA_PRODUCT_NAME=CUDA
NV_CUDA_CUDART_VERSION=12.6.77-1
NCCL_PROTO=simple
CUDA_VERSION=12.6.3
CONDA_PROMPT_MODIFIER=(soberplus) 
NCCL_AVOID_RECORD_STREAMS=1
NCCL_PXN_DISABLE=0
HF_HOME=/checkpoints-fsx/yibiaoy-sandbox/HF
DS_SKIP_CUDA_CHECK=1
NCCL_ASYNC_ERROR_HANDLING=1
LIBRARY_PATH=/usr/local/cuda/lib64/stubs
NV_CUDA_LIB_VERSION=12.6.3-1
PROMPTS_PATH=/code-fsx/yibiaoy-sandbox/SoberReasoningPlus/prompts.json
CUDA_DEVICE_MAX_CONNECTIONS=1
TORCH_NCCL_AVOID_RECORD_STREAMS=1
CUDA_INSTALL_PATH=/usr/local/cuda
NV_LIBNCCL_PACKAGE=libnccl2=2.23.4-1+cuda12.6
LD_LIBRARY_PATH=/opt/aws-ofi-nccl/lib:/opt/nccl/lib:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib/:/usr/local/cuda:/opt/nccl/lib/x86_64-linux-gnu:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
NCCL_IGNORE_DISABLED_P2P=1
OMP_NUM_THREADS=8
CUDA_HOME=/usr/local/cuda
CUDA_MODULE_LOADING=LAZY
PATH=/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/bin:/code-fsx/yibiaoy-sandbox/miniconda3/condabin:/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/usr/local/cuda:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
NV_LIBNCCL_PACKAGE_NAME=libnccl2
NV_LIBNCCL_PACKAGE_VERSION=2.23.4-1
[2025-08-23T03:45:39+00:00] >>> RunPlan: model=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B task_list=aime24
aime25
amc23
math_500
minerva
olympiadbench seeds=VAR temp=0.0 top_p=0.6 max_tokens=32768 dtype=bfloat16 max_model_length=34816
---- 2025-08-23T03:45:39+00:00 RUN START ----
+ python /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/main.py --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --task 'custom|aime24|0|0' --temperature 0.0 --top_p 0.6 --output_dir /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/outputs --max_new_tokens 32768 --max_model_length 34816 --custom_tasks_directory /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/lighteval_tasks.py --system_prompt 'You are a helpful assistant.' --use_chat_template --dtype bfloat16 --max_num_seqs 256 --max_num_batched_tokens 262144 --tensor_parallel_size 4 --pipeline_parallel_size 1 --data_parallel_size 1 --seed 0
[I823 03:45:41.710879478 debug.cpp:50] [c10d] The debug level is set to INFO.
INFO 08-23 03:46:19 [__init__.py:244] Automatically detected platform cuda.
usage: main.py [-h] --model MODEL [--dtype DTYPE]
               [--tensor-parallel-size TENSOR_PARALLEL_SIZE]
               [--max-model-length MAX_MODEL_LENGTH]
               [--max-num-batched-tokens MAX_NUM_BATCHED_TOKENS]
               [--max-num-seqs MAX_NUM_SEQS]
               [--gpu-memory-utilization GPU_MEMORY_UTILIZATION]
               [--extra-vllm-args EXTRA_VLLM_ARGS] [--temps TEMPS]
               [--top-ps TOP_PS] [--seeds SEEDS]
               [--max-new-tokens MAX_NEW_TOKENS] --tasks TASKS
               [--batch-size BATCH_SIZE] [--limit-per-task LIMIT_PER_TASK]
               [--system-prompt SYSTEM_PROMPT] [--output_dir OUTPUT_DIR]
main.py: error: unrecognized arguments: --temperature 0.0 --top_p 0.6 --max_new_tokens 32768 --max_model_length 34816 --custom_tasks_directory /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/lighteval_tasks.py --system_prompt You are a helpful assistant. --use_chat_template --max_num_seqs 256 --max_num_batched_tokens 262144 --tensor_parallel_size 4 --pipeline_parallel_size 1 --data_parallel_size 1
End: 2025-08-23T03:46:35+00:00
