---- 2025-08-22T23:26:09+00:00 RUN START ----
+ python /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/main.py --model deepseek-ai/DeepSeek-R1-Distill-Qwen-14B --task 'custom|amc23|0|0' --temperature 0.0 --top_p 0.6 --output_dir /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/outputs --max_new_tokens 32768 --max_model_length 34816 --custom_tasks_directory /code-fsx/yibiaoy-sandbox/SoberReasoningPlus/lighteval_tasks.py --system_prompt 'You are a helpful assistant.' --use_chat_template --dtype bfloat16 --max_num_seqs 256 --max_num_batched_tokens 262144 --tensor_parallel_size 8 --pipeline_parallel_size 1 --data_parallel_size 1 --seed 3
[I822 23:26:11.040886579 debug.cpp:50] [c10d] The debug level is set to INFO.
INFO 08-22 23:26:58 [__init__.py:244] Automatically detected platform cuda.
Using seed: 3
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/multiprocessing/spawn.py", line 131, in _main
    prepare(preparation_data)
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/multiprocessing/spawn.py", line 246, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/multiprocessing/spawn.py", line 297, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen runpy>", line 287, in run_path
  File "<frozen runpy>", line 98, in _run_module_code
  File "<frozen runpy>", line 88, in _run_code
  File "/code-fsx/yibiaoy-sandbox/SoberReasoningPlus/main.py", line 21, in <module>
    from lm_eval import evaluator
ModuleNotFoundError: No module named 'lm_eval'
Traceback (most recent call last):
  File "/code-fsx/yibiaoy-sandbox/SoberReasoningPlus/main.py", line 149, in <module>
    main()
  File "/code-fsx/yibiaoy-sandbox/SoberReasoningPlus/main.py", line 135, in main
    log_samples=False,
   ^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/pipeline.py", line 156, in __init__
    self.model = self._init_model(model_config, model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/pipeline.py", line 200, in _init_model
    return load_model(config=model_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/models/model_loader.py", line 107, in load_model
    return load_model_with_accelerate_or_default(config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/models/model_loader.py", line 198, in load_model_with_accelerate_or_default
    model = VLLMModel(config=config)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/models/vllm/vllm_model.py", line 114, in __init__
    self.model = self._create_auto_model(config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/lighteval/models/vllm/vllm_model.py", line 184, in _create_auto_model
    model = LLM(**self.model_args)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 271, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/engine/llm_engine.py", line 501, in from_engine_args
    return engine_cls.from_vllm_config(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py", line 124, in from_vllm_config
    return cls(vllm_config=vllm_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py", line 101, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 75, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 503, in __init__
    super().__init__(
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 403, in __init__
    with launch_core_engines(vllm_config, executor_class,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 434, in launch_core_engines
    wait_for_engine_startup(
  File "/code-fsx/yibiaoy-sandbox/miniconda3/envs/soberplus/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 484, in wait_for_engine_startup
    raise RuntimeError("Engine core initialization failed. "
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
